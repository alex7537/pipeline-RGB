import pyrealsense2 as rs
import numpy as np
import cv2
import json
import os
import open3d as o3d   # â­ æ–°å¢ï¼šç”¨äºä¿å­˜ç‚¹äº‘

out_dir = "rs_test_output"
os.makedirs(out_dir, exist_ok=True)

# 1. é…ç½®å¹¶å¯åŠ¨ç®¡çº¿
pipeline = rs.pipeline()
config = rs.config()

# â­ æ–°å¢ï¼šæŒ‡å®šä½¿ç”¨å“ªä¸€å° RealSenseï¼ˆè¿™å°æ˜¯ä½ ç”¨æ¥åš IR+Color+Depth çš„é‚£å°ï¼‰
serial_ir_cam = "923322072633"          # â† æ¢æˆä½ çœŸå®çš„åºåˆ—å·
config.enable_device(serial_ir_cam)

# åˆ†è¾¨ç‡å¯ä»¥æŒ‰éœ€æ”¹ï¼Œåé¢æœ€å¥½å’Œä½ ç®—æ³•ä¸€è‡´
W, H = 640, 480
config.enable_stream(rs.stream.color, W, H, rs.format.bgr8, 30)
config.enable_stream(rs.stream.depth, W, H, rs.format.z16, 30)
config.enable_stream(rs.stream.infrared, 1, W, H, rs.format.y8, 30)  # å·¦ IR
config.enable_stream(rs.stream.infrared, 2, W, H, rs.format.y8, 30)  # å³ IR

# å¯¹é½ depth â†’ color
align = rs.align(rs.stream.color)

print("Starting pipeline...")
profile = pipeline.start(config)

# æ·±åº¦ scaleï¼ˆæŠŠ uint16 è½¬æˆç±³è¦ç”¨ï¼‰
depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()
print("Depth scale:", depth_scale)

# 2. è·³è¿‡å‰é¢å‡ å¸§ï¼Œè®©è‡ªåŠ¨æ›å…‰ç¨³å®š
for _ in range(30):
    frames = pipeline.wait_for_frames()

frames = pipeline.wait_for_frames()
aligned = align.process(frames)

# raw colorï¼ˆç»™ FS å¯¹é½ç”¨ï¼‰
color_raw_frame = frames.get_color_frame()
# aligned color + depthï¼ˆç»™ RealSense ç‚¹äº‘ç”¨ï¼‰
color_frame = aligned.get_color_frame()
depth_frame = aligned.get_depth_frame()

ir_left_frame  = frames.get_infrared_frame(1)
ir_right_frame = frames.get_infrared_frame(2)

if not color_frame or not depth_frame:
    raise RuntimeError("No frames received")

# 3. è½¬æˆ numpy
color_raw = np.asanyarray(color_raw_frame.get_data())      # HxWx3, BGR
color = np.asanyarray(color_frame.get_data())       # HxWx3, uint8 (BGR)
depth = np.asanyarray(depth_frame.get_data())       # HxW, uint16
ir_left  = np.asanyarray(ir_left_frame.get_data())  # HxW, uint8
ir_right = np.asanyarray(ir_right_frame.get_data()) # HxW, uint8

# âœ… ç°åº¦ â†’ ä¼ªä¸‰é€šé“ RGB (å’Œä½  C++ é‡Œçš„ cv::cvtColor ä¸€æ ·)
ir_left_rgb  = cv2.cvtColor(ir_left,  cv2.COLOR_GRAY2RGB)   # HxWx3
ir_right_rgb = cv2.cvtColor(ir_right, cv2.COLOR_GRAY2RGB)   # HxWx3

print("Color shape:", color.shape)
print("Depth shape:", depth.shape)

# =============================
#  ğŸ”¥ æ­£ç¡®æå– IR stereo å†…å‚ ğŸ”¥
# =============================

intr_left = ir_left_frame.profile.as_video_stream_profile().intrinsics
intr_right = ir_right_frame.profile.as_video_stream_profile().intrinsics



# stereo baseline (å•ä½ï¼šç±³)
extr = ir_left_frame.profile.get_extrinsics_to(ir_right_frame.profile)
baseline = np.linalg.norm(extr.translation)

K_left = {
    "width": intr_left.width,
    "height": intr_left.height,
    "fx": intr_left.fx,
    "fy": intr_left.fy,
    "cx": intr_left.ppx,
    "cy": intr_left.ppy,
    "baseline_m": baseline
}

print("IR Left K = ", K_left)
print("Baseline = ", baseline)

# =============================
#  â­ æ–°å¢ï¼šç”¨ color + depth ç›´æ¥ç”Ÿæˆ RealSense ç‚¹äº‘ â­
# =============================

# ä½¿ç”¨å¯¹é½åˆ° color çš„ depthï¼Œå¯¹åº”çš„å†…å‚ä¹Ÿç”¨ color ç›¸æœºçš„
intr_color_raw = color_raw_frame.profile.as_video_stream_profile().intrinsics
fx, fy = intr_color_raw.fx, intr_color_raw.fy
cx, cy = intr_color_raw.ppx, intr_color_raw.ppy

# â­ æ–°å¢ï¼šä¿å­˜ Color ç›¸æœºå†…å‚
K_color = {
    "width":  intr_color_raw.width,
    "height": intr_color_raw.height,
    "fx":     intr_color_raw.fx,
    "fy":     intr_color_raw.fy,
    "cx":     intr_color_raw.ppx,
    "cy":     intr_color_raw.ppy,
}
with open(os.path.join(out_dir, "color_intrinsics.json"), "w") as f:
    json.dump(K_color, f, indent=2)

# depth è½¬ç±³
z = depth.astype(np.float32) * depth_scale  # HxW, float32 (meters)

H_d, W_d = z.shape
vs, us = np.meshgrid(np.arange(H_d), np.arange(W_d), indexing="ij")

X = (us - cx) * z / fx
Y = (vs - cy) * z / fy
Z = z

valid = Z > 0
pts = np.stack((X[valid], Y[valid], Z[valid]), axis=-1)

# é¢œè‰²ä» BGR â†’ RGBï¼Œå†å½’ä¸€åŒ–
color_rgb = cv2.cvtColor(color, cv2.COLOR_BGR2RGB)
cols = color_rgb[valid].reshape(-1, 3) / 255.0

pcd_rs = o3d.geometry.PointCloud()
pcd_rs.points = o3d.utility.Vector3dVector(pts)
pcd_rs.colors = o3d.utility.Vector3dVector(cols)

ply_path = os.path.join(out_dir, "cloud_rs_capture.ply")
o3d.io.write_point_cloud(ply_path, pcd_rs)
print(f"RealSense point cloud saved to: {ply_path}")
print("Valid points:", pts.shape[0])

# 5. ä¿å­˜å›¾åƒå’Œ IR å†…å‚

# ç»™ FS IRâ†’RGB å¯¹é½ç”¨çš„åŸå§‹ RGB
cv2.imwrite(os.path.join(out_dir, "color_raw_0000.png"), color_raw)

cv2.imwrite(os.path.join(out_dir, "color_0000.png"), color)
cv2.imwrite(os.path.join(out_dir, "depth_0000.png"), depth)           # uint16, åŸå§‹depth
cv2.imwrite(os.path.join(out_dir, "ir_left_0000.png"), ir_left_rgb)
cv2.imwrite(os.path.join(out_dir, "ir_right_0000.png"), ir_right_rgb)

# save intrinsics for stereo (IR)
with open(os.path.join(out_dir, "ir_intrinsics.json"), "w") as f:
    json.dump(K_left, f, indent=2)

# ====== ä¿å­˜ IR(left) â†’ Color å¤–å‚ ======
extr_ir2color = ir_left_frame.profile.get_extrinsics_to(color_raw_frame.profile)
R_ir2color = np.array(extr_ir2color.rotation).reshape(3, 3)
t_ir2color = np.array(extr_ir2color.translation).reshape(3, 1)

extr_dict = {
    "R": R_ir2color.tolist(),   # 3x3
    "t": t_ir2color.tolist(),   # 3x1
}
with open(os.path.join(out_dir, "ir2color_extrinsics.json"), "w") as f:
    json.dump(extr_dict, f, indent=2)

pipeline.stop()
print("Saved images, intrinsics and point cloud to:", out_dir)
